# 缺失值处理
姓名：朱海波            
学号：16051336

---
## 1.本项目特征工程之后数据集产生缺失值的原因
```
#计算用户在一个商家的行为总数占该用户所有行为的比率
df['log_count_ratio'] = df.log_count / df.log_count_u_all
```
`df.log_count_u_all`为空，作为分母，分母不能为空，所以产生缺失值。  

这里的`df.log_count_u_all`有80个值为空，也就是说，这些用户从5月开始到双十一的当天都没有任何行为，但是这些用户的`label`值却不是`-1`。讲道理不应该存在这一部分数据。或者说这部分数据本来就是属于错误数据，对于接下来的模型预测不会有什么好的影响。但是出于对数据的保留，我们还是选择了对其进行填充缺失值而吗，没有选择删除。

这个缺失值不是在`数据预处理阶段`发现的，而是在运用`RandomForest随机森林模型`时发现的。我认为`数据预处理`其实和`特征工程`之间是没有什么完全的先后关系的，很多时候这两者都是同时进行的。甚至于`数据预处理`、`特征工程`、`模型训练`这三者之间都没有什么固定的界限。有时候不必将其中一项做到十分完美再进行下一项工作，三者都是相辅相成的。我们可以通过`特征工程`来发现`数据预处理`中的不足，也可以通过`模型训练`的结果来发现`特征工程`的不足。

## 2.处理缺失值的原因
在处理完特征工程之后，jupyter提示报错`ValueError: Input contains NaN, infinity or a value too large for dtype('float64')`。但是我的组员在相同的数据集下使用`Light GBM`模型就没有这个问题，`Light GBM`模型对缺失值可以自动处理。

## 3.缺失值处理的基本思路

* 1.删除：最简单最直接的方法，很多时候也是最有效的方法，这种做法的缺点是可能会导致信息丢失。删除有缺失数据的样本删除有过多缺失数据的特征
* 2.补全：用规则或模型将缺失数据补全，这种做法的缺点是可能会引入噪声。平均数、中位数、众数、最大值、最小值、固定值、插值等等建立一个模型来“预测”缺失的数据。（`KNN`, `Matrix completion`等方法）引入虚拟变量(`dummy variable`)来表征是否有缺失，是否有补全。
* 3.忽略：有一些模型，如`LightGBm`，自身能够处理数据缺失的情况，在这种情况下不需要对缺失数据做任何的处理，这种做法的缺点是在模型的选择上有局限。

## 4.处理缺失值的方式
1.对于缺失值较多的特征处理：         
如果某特征的缺失值过多，建议直接将该特征舍弃，否则可能会引入较大的噪声，对结果造成不良的影响。

2.对于缺失值较少的特征处理：            
* 1.把`NaN`直接作为一个特征，用`0`来表示:   
`.fillna(0) `
* 2.用均值/中值/分位数/众数/随机值等填充：         
`.fillna(data_train.mean())`
* 3.用上下数据填充     
`.fillna(method='pad')`表示用前一个数据代替`NaN`。      
`.fillna(method='bfill')`表示用前一个数据代替`NaN`。
* 4.用插值法填充
插值法就是通过两点（x0，y0），（x1，y1）估计中间点的值      
`data_train.interpolate() `
* 5.用算法拟合填充，例如使用随机森林算法，利用数据表中某些没有缺失的特征属性来预测某特征属性的缺失值。我个人觉得这个方法可以说是最有用又最花时间的，这个方法需要用到模型训练，可以先一步模型训练填充完缺失值，然后在进行完整数据集的模型训练。但是这种方式有一个根本缺陷，如果其他变量和缺失变量无关，则预测的结果无意义。如果预测结果相当准确，则又说明这个变量是没必要加入建模的。一般情况下，介于两者之间。


我十分赞同知乎上的一位朋友(id：禅羽)对缺失值填充的看法，她认为：
```
看缺失值占比， 本来就是个估计数，要是就缺少一点点可以pass。占比一定，如果有时间序列特征，就利用已有的数据，利用时间序列模型计算一个数字填充；
如果是普通的， 看数字的分布特征，简单就用正态分布，做一个不影响整体估计数的计算出缺失值； 根据数据库特征补缺失值。 
市面上有专门的缺失值处理书，整整一本都在搞这个东西。 
我觉得缺失值的填补的精髓就是不能影响整体的估计，它就只能是占个位置，让程序运行下去，让已有的别的属性的值能发挥作用。 填补数与已有的数的分布、特征应符合，不能因为这些数字的变更导致估计值变化。
```
